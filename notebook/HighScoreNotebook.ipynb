{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2451,"status":"ok","timestamp":1696658548701,"user":{"displayName":"이운현","userId":"10250896466735360270"},"user_tz":-540},"id":"Opfh1u6mOSjb","outputId":"d3cc1baf-8486-405c-9487-d48d82abb91e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir(\"./drive/MyDrive/git_project/TextClassification/src\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49722,"status":"ok","timestamp":1696658607782,"user":{"displayName":"이운현","userId":"10250896466735360270"},"user_tz":-540},"id":"tIqGPDp-umlG","outputId":"8c20ff0a-6577-45d8-c80f-3640d5612deb"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-10-07 06:02:38--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.226.210.15, 13.226.210.25, 13.226.210.111, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.226.210.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1523785255 (1.4G) [application/zip]\n","Saving to: ‘crawl-300d-2M.vec.zip’\n","\n","crawl-300d-2M.vec.z 100%[===================\u003e]   1.42G  39.4MB/s    in 49s     \n","\n","2023-10-07 06:03:27 (29.6 MB/s) - ‘crawl-300d-2M.vec.zip’ saved [1523785255/1523785255]\n","\n"]}],"source":["!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83430,"status":"ok","timestamp":1696658693383,"user":{"displayName":"이운현","userId":"10250896466735360270"},"user_tz":-540},"id":"BcjuBJAhu40l","outputId":"3dee13c4-9d29-4d77-95c0-b2daf80a4d4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  crawl-300d-2M.vec.zip\n","  inflating: crawl-300d-2M.vec       \n"]}],"source":["!unzip crawl-300d-2M.vec.zip"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":11970,"status":"ok","timestamp":1696658790881,"user":{"displayName":"이운현","userId":"10250896466735360270"},"user_tz":-540},"id":"CJg4zsoXOGY1"},"outputs":[],"source":["import numpy as np\n","np.random.seed(42)\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score\n","\n","from keras.models import Model\n","from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate\n","from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n","from keras.preprocessing import text, sequence\n","from keras.callbacks import Callback\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import os\n","os.environ['OMP_NUM_THREADS'] = '4'\n","\n","\n","EMBEDDING_FILE = './crawl-300d-2M.vec'\n","\n","train = pd.read_csv('../data/train.csv')\n","test = pd.read_csv('../data/test.csv')\n","submission = pd.read_csv('../data/sample_submission.csv')\n","\n","X_train = train[\"comment_text\"].fillna(\"fillna\").values\n","y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n","X_test = test[\"comment_text\"].fillna(\"fillna\").values"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":230176,"status":"ok","timestamp":1696659045616,"user":{"displayName":"이운현","userId":"10250896466735360270"},"user_tz":-540},"id":"jOhmKvSgOyIu"},"outputs":[],"source":["max_features = 30000\n","maxlen = 100\n","embed_size = 300\n","\n","tokenizer = text.Tokenizer(num_words=max_features)\n","tokenizer.fit_on_texts(list(X_train) + list(X_test))\n","X_train = tokenizer.texts_to_sequences(X_train)\n","X_test = tokenizer.texts_to_sequences(X_test)\n","x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n","x_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n","\n","\n","def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n","embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1V-z6J5dssPue-7-0CQDhkV1rjcULfl45"},"id":"cYbkZbDJvwUN","outputId":"23320134-f0e2-4abb-937b-5653aac78d1f"},"outputs":[],"source":["embeddings_index.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOstAcFVvrYo"},"outputs":[],"source":["\n","word_index = tokenizer.word_index\n","nb_words = min(max_features, len(word_index))\n","embedding_matrix = np.zeros((nb_words, embed_size))\n","for word, i in word_index.items():\n","    if i \u003e= max_features: continue\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n","\n","\n","class RocAucEvaluation(Callback):\n","    def __init__(self, validation_data=(), interval=1):\n","        super(Callback, self).__init__()\n","\n","        self.interval = interval\n","        self.X_val, self.y_val = validation_data\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        if epoch % self.interval == 0:\n","            y_pred = self.model.predict(self.X_val, verbose=0)\n","            score = roc_auc_score(self.y_val, y_pred)\n","            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-5o7097vnwG"},"outputs":[],"source":["\n","\n","def get_model():\n","    inp = Input(shape=(maxlen, ))\n","    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n","    x = SpatialDropout1D(0.2)(x)\n","    x = Bidirectional(GRU(80, return_sequences=True))(x)\n","    avg_pool = GlobalAveragePooling1D()(x)\n","    max_pool = GlobalMaxPooling1D()(x)\n","    conc = concatenate([avg_pool, max_pool])\n","    outp = Dense(6, activation=\"sigmoid\")(conc)\n","\n","    model = Model(inputs=inp, outputs=outp)\n","    model.compile(loss='binary_crossentropy',\n","                  optimizer='adam',\n","                  metrics=['accuracy'])\n","\n","    return model\n","\n","model = get_model()\n","\n","\n","batch_size = 32\n","epochs = 2\n","\n","X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)\n","RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n","\n","hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),\n","                 callbacks=[RocAuc], verbose=2)\n","\n","\n","y_pred = model.predict(x_test, batch_size=1024)\n","submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\n","submission.to_csv('submission.csv', index=False)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOeLLquwCoHtadJfQeAFHaZ","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}